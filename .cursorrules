# Course Generator Agent - Cursor Rules

## Project Overview

This is an AI-powered course generation system that creates comprehensive educational content from topics or PDF syllabi. The system uses LangChain/LangGraph for orchestration and supports multiple LLM providers.

## Technology Stack

- **Framework**: LangGraph (state machine orchestration), LangChain (LLM abstractions)
- **Language**: Python 3.10+
- **Data Models**: Pydantic v2 for all schemas
- **LLM Providers**: Mistral, Gemini, Groq, OpenAI, DeepSeek (text), Pixtral (vision)
- **TTS Engines**: Edge TTS (default), Coqui TTS (optional)
- **PDF Processing**: Docling with EasyOCR/ocrmac (optional `pdf-extraction` group)
- **ML / Transformers**: torch, torchaudio, transformers (optional `ml` group)
- **PDF Book Generation**: LaTeX via XeLaTeX/pdflatex with BibTeX
- **Book Search**: Open Library API (no API key required)
- **Tracing**: LangSmith for observability

### Dependency Groups

Default install (`pip install -e .`) is lightweight (~500 MB) for text generation. Heavy packages are optional:

| Group | Packages | Use Case |
|-------|----------|----------|
| `pdf-extraction` | docling, easyocr | PDF syllabus → Markdown |
| `ml` | torch, torchaudio, transformers | ML inference |
| `all` | pdf-extraction + ml | Full local development |
| `macos-ocr` | ocrmac | macOS-only native OCR |
| `evaluation` | textstat, langdetect, nltk, sentence-transformers | Quality evaluation |
| `coqui-tts` | TTS | Local TTS (conflicts with docling) |

## Code Style Rules

### Pydantic Models
- Use Pydantic v2 syntax: `Field(...)` with description, `model_dump()`, `model_validate()`
- All models inherit from `BaseModel`
- Use `Literal` types for constrained string choices
- Use `Optional[T]` with `Field(default=None)` for nullable fields
- Document all fields with `description` parameter

### Type Hints
- Always use type hints for function parameters and return values
- Use `list[T]` instead of `List[T]` (Python 3.9+ syntax)
- Use `dict[K, V]` instead of `Dict[K, V]`
- Use `str | None` instead of `Optional[str]` where appropriate

### Docstrings
- Use Google-style docstrings with Args, Returns, and Raises sections
- Include example usage for complex functions
- Document all public functions and classes

### Factory Pattern
- Use factory functions for creating instances of LLMs, tools, and search providers
- Factory functions should accept `provider: str` as first argument
- Register implementations in a `PROVIDERS` or `BUILDERS` dict
- Provide `available_*()` helper functions listing registered providers

Example:
```python
BUILDERS: Dict[str, Builder] = {
    "mistral": build_mistral_chat_model,
    "gemini": build_gemini_chat_model,
}

def create_text_llm(provider: str, **kwargs) -> BaseChatModel:
    builder = BUILDERS[provider.lower()]
    return builder(**kwargs)
```

## Architecture Guidelines

### Agent Structure
Each agent lives in `agents/{agent_name}/` with:
- `__init__.py` - Exports main functions
- `agent.py` - Core agent logic and LangGraph nodes
- `prompts.py` - All prompt templates using `ChatPromptTemplate`

### State Management
- `CourseState` is the main state object passed through workflows
- `CourseConfig` contains immutable configuration (agents should NOT modify it)
- Agents modify content fields: `modules`, `title`, research data
- Use `state.config.{setting}` to access configuration values

### Workflow Patterns
- Build workflows using `StateGraph` from LangGraph
- Use `START` and `END` constants for graph edges
- Node functions signature: `def node_name(state: CourseState, config: RunnableConfig = None) -> CourseState`
- Use `Send` pattern for parallel processing of modules/sections
- Use `RetryPolicy` for automatic retry on parse failures

### Tool Integration
- Tools live in `tools/{tool_type}/` directories
- Each tool type has a `factory.py` with `create_*()` function
- Implement clients in provider-specific subdirectories (e.g., `tools/websearch/ddg/client.py`)

### Available Tools
- `tools/websearch/` - Web search (DDG, Tavily, Wikipedia)
- `tools/imagesearch/` - Image search (Bing, DDG, Freepik, Google)
- `tools/booksearch/` - Book metadata via Open Library API
- `tools/pdf2md/` - PDF to Markdown via Docling
- `tools/pdf_book/` - PDF book generation via LaTeX
- `tools/podcast/` - TTS audio generation (Edge TTS, Coqui TTS)

### LLM Provider Abstraction
- All LLM calls go through `LLMs/text2text/factory.py` or `LLMs/imagetext2text/factory.py`
- Use `create_text_llm(provider=...)` to instantiate LLMs
- Use `resolve_text_model_name(provider)` to get model name from environment
- Model names come from environment variables: `{PROVIDER}_MODEL_NAME`

## Domain-Specific Rules

### Course Structure Hierarchy
```
CourseState
├── config: CourseConfig (immutable)
├── research: CourseResearch (optional)
├── title: str
├── modules: List[Module]
│   └── submodules: List[Submodule]
│       └── sections: List[Section]
│           ├── theory: str
│           ├── html: List[HtmlElement]
│           ├── activities: ActivitiesSection
│           └── meta_elements: MetaElements
└── bibliography: CourseBibliography (optional)
    ├── modules: List[ModuleBibliography]
    │   └── books: List[BookReference]
    └── all_books: List[BookReference] (deduplicated)
```

### Bibliography Configuration
- `generate_bibliography: bool = False` - Enable book bibliography generation
- `bibliography_books_per_module: int = 5` - Target books per module
- Uses Open Library API for validation + APA 7 citation formatting

### HTML Element Types
- Simple: `p` (paragraph), `ul` (list)
- Structured: `quote`, `table`
- Interactive: `paragraphs`, `accordion`, `tabs`, `carousel`, `flip`, `timeline`, `conversation`

### Activity Types
- Quiz: `order_list`, `fill_gaps`, `swipper`, `linking_terms`, `multiple_choice`, `multi_selection`
- Application: `group_activity`, `discussion_forum`, `individual_project`, `open_ended_quiz`

### Research Phase
- Research is conducted in ENGLISH regardless of target language
- Research output feeds into index generation for better structure
- Use `enable_research=True` in CourseConfig to enable

## Environment Configuration

### API Keys Pattern
- Store API keys in `env.secrets` (gitignored)
- Copy from `env.example` as template
- Load with `source env.secrets`
- Access via `os.getenv("PROVIDER_API_KEY")`

### Required Environment Variables
```bash
# LLM Providers
MISTRAL_API_KEY=
GEMINI_API_KEY=
OPENAI_API_KEY=
GROQ_API_KEY=
DEEPSEEK_API_KEY=
PIXTRAL_API_KEY=

# Model Names (optional, have defaults)
MISTRAL_MODEL_NAME=mistral-small-latest
GEMINI_MODEL_NAME=gemini-flash-latest
OPENAI_MODEL_NAME=gpt-4o-mini

# LangSmith Tracing
LANGCHAIN_TRACING_V2=false
LANGSMITH_API_KEY=

# Web Search
TAVILY_API_KEY=
```

## Evaluation Framework

### Evaluator Pattern
- All evaluators inherit from `BaseEvaluator` in `evaluators/base.py`
- Use `RubricScore` model for 1-5 scale scoring with reasoning
- Implement `evaluate()` method returning structured scores
- Use `evaluate_with_rubric()` helper for LLM-as-judge pattern

### Running Evaluations
```bash
# Create dataset from outputs
python3 -m evaluation.dataset create-dataset --inputs output/*.json

# Run evaluation
python3 -m evaluation.workflow evaluate --dataset my-courses
```

## Output Management

- All outputs go to `output/{course_name}_{timestamp}/` directories
- Use `OutputManager` class for consistent output handling
- Save intermediate steps with `output_mgr.save_step("step_name", state)`
- Save final outputs with `output_mgr.save_final(state)` and `output_mgr.save_modules(state)`

### Output Files
- `course.json` - Full course data structure
- `module_N.json` - Individual module files
- `bibliography.json` - Book references (if enabled)
- `podcast/` - Audio files and conversation JSONs
- `book/` - PDF book via LaTeX (post-processing)
- `video_html/` - Simplified JSONs for video (post-processing)

## Common Pitfalls

1. **Don't modify CourseConfig** - It's meant to be immutable after initialization
2. **Always strip markdown fences** - LLMs often wrap JSON in ```json blocks
3. **Handle parse failures** - Use `RetryWithErrorOutputParser` for robust parsing
4. **Respect concurrency settings** - Use `state.config.concurrency` for parallel operations
5. **Check for None** - Many fields like `html`, `activities`, `meta_elements` can be None

## SQL Safety Rule

CRITICAL: Never generate, suggest, or execute SQL statements containing DROP (e.g., DROP TABLE, DROP DATABASE). This is an absolute prohibition to prevent data loss.

If data deletion is needed, suggest:
- `TRUNCATE TABLE [table_name]` for emptying tables
- `DELETE FROM [table_name] WHERE [condition]` for selective deletion

## Testing

- Run workflows with small `total_pages` values for quick iteration
- Use `--total-pages 2` flag for minimal test runs
- Check LangSmith traces for debugging LLM calls
- Evaluation framework provides automated quality metrics

## Running Workflows

```bash
# Generate course from topic
python3 -m main.workflow --total-pages 10

# Generate course with bibliography
python3 -m main.workflow --total-pages 10 --generate-bibliography

# Generate course from PDF syllabus
python3 -m main.workflow_pdf path/to/syllabus.pdf

# Generate podcast from PDF (skips activities/HTML/images)
python3 -m main.workflow_pdf2podcast path/to/syllabus.pdf --target-words 600
```

## Post-Processing Tools

```bash
# Generate PDF book from completed course
python3 -m tools.pdf_book output/course_name/course.json

# Simplify module JSON for video generation
python3 -m agents.video_html output/course_name/module_0.json

# Preview simplified module without saving
python3 -m agents.video_html output/course_name/module_0.json --preview
```

## New Agent Capabilities

### Bibliography Generator (`agents/bibliography_generator/`)
- Hybrid LLM + Open Library API for book recommendations
- APA 7 citation formatting
- Deduplication across modules
- Key function: `generate_course_bibliography(state)`

### Video HTML Agent (`agents/video_html/`)
- Deterministic (no LLM) JSON simplification
- Extracts essential fields for video generation
- Truncates HTML content arrays to first item
- Key function: `simplify_module_from_path(input_path)`

### Podcast Generator (`agents/podcast_generator/`)
- Two-speaker dialogue generation
- Edge TTS (cloud) or Coqui TTS (local) audio synthesis
- Background music with intro/outro fades
- MP3 metadata embedding
- Key function: `generate_module_podcast(course_path, module_idx)`









